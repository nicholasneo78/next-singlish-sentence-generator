{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "EDA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE6BFrf-Vva1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "070797d0-f2fb-47c0-d73c-404cf30e6981"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuopYNePVhuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Flatten\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, Conv1D, GlobalAveragePooling1D, concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "from keras.callbacks import CSVLogger, ReduceLROnPlateau, ModelCheckpoint \n",
        "import pickle\n",
        "import random"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HynxemjhVhuc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a63ef232-f2c8-4327-bd73-7dff50f40212"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG1YefClVhuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "    # open the file as read only\n",
        "    file = open(filename, 'r')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    # close the file\n",
        "    file.close()\n",
        "    return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP3M_v8zVhu9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "692fa04e-7d21-490b-8e46-b77a2f930ac6"
      },
      "source": [
        "# load document\n",
        "filename = './finalData/SgCorpus.txt'\n",
        "\n",
        "# for google drive\n",
        "filename = './drive/My Drive/next-sentence-predictor/finalData/SgCorpus.txt'\n",
        "\n",
        "# for google drive & smaller dataset\n",
        "filename = './drive/My Drive/next-sentence-predictor/finalData/dataBatch2.txt'\n",
        "\n",
        "doc = load_doc(filename)\n",
        "print(doc[:505])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " seriously. what's with the sp internet connection this few days. can not connect to the internet. later attendance drop because i cannot enter the ats code.\n",
            ".i like him but . he do not like me.why .be he likes girls that look more mature\n",
            ".is there a cycling club in sp? i saw this guy in the sp attire around mac area, he`s kinda cute hehe .admin lowbatt: yes there is check it out here: \n",
            ".am i the only one in sp who likes cartoons? it seems that i have quite a number of coursemates who love animes but\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwL4D5PfVhvE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        " \n",
        "# turn a doc into clean tokens\n",
        "def clean_doc(doc):\n",
        "    # replace '--' with a space ' '\n",
        "    doc = doc.replace('--', ' ')\n",
        "    # split into tokens by white space\n",
        "    tokens = doc.split()\n",
        "    # remove punctuation from each token\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    tokens = [w.translate(table) for w in tokens]\n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    # make lower case\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCZb520zVhvO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "d754ebc1-6d65-4c90-8d15-222e1e8dc6a7"
      },
      "source": [
        "# clean document\n",
        "tokens = clean_doc(doc)\n",
        "print(tokens[:200])\n",
        "print('Total Tokens: %d' % len(tokens))\n",
        "print('Unique Tokens: %d' % len(set(tokens)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['seriously', 'whats', 'with', 'the', 'sp', 'internet', 'connection', 'this', 'few', 'days', 'can', 'not', 'connect', 'to', 'the', 'internet', 'later', 'attendance', 'drop', 'because', 'i', 'cannot', 'enter', 'the', 'ats', 'code', 'i', 'like', 'him', 'but', 'he', 'do', 'not', 'like', 'mewhy', 'be', 'he', 'likes', 'girls', 'that', 'look', 'more', 'mature', 'is', 'there', 'a', 'cycling', 'club', 'in', 'sp', 'i', 'saw', 'this', 'guy', 'in', 'the', 'sp', 'attire', 'around', 'mac', 'area', 'hes', 'kinda', 'cute', 'hehe', 'admin', 'lowbatt', 'yes', 'there', 'is', 'check', 'it', 'out', 'here', 'am', 'i', 'the', 'only', 'one', 'in', 'sp', 'who', 'likes', 'cartoons', 'it', 'seems', 'that', 'i', 'have', 'quite', 'a', 'number', 'of', 'coursemates', 'who', 'love', 'animes', 'but', 'nobody', 'else', 'seem', 'to', 'share', 'my', 'interest', 'in', 'cartoons', 'hi', 'has', 'anyone', 'picked', 'up', 'a', 'green', 'power', 'adapter', 'that', 'comes', 'with', 'usb', 'ports', 'and', 'a', 'three', 'pin', 'outlet', 'on', 'it', 'i', 'have', 'left', 'it', 'at', 'spectrum', 'yesterday', 'anyone', 'found', 'it', 'pls', 'let', 'me', 'know', 'thaanks', 'it', 'is', 'my', 'birthday', 'today', 'and', 'i', 'got', 'wishes', 'and', 'nope', 'do', 'not', 'see', 'yourself', 'in', 'that', 'light', 'you', 'may', 'not', 'look', 'the', 'most', 'handsome', 'gorgeous', 'what', 'matters', 'most', 'is', 'your', 'personality', 'and', 'character', 'for', 'a', 'good', 'start', 'see', 'the', 'good', 'side', 'of', 'yourself', 'on', 'your', 'own', 'acknowledge', 'that', 'good', 'and', 'you', 'will', 'find', 'that', 'your', 'life']\n",
            "Total Tokens: 752464\n",
            "Unique Tokens: 39789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIT1iXTrVhvY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04d6c184-c31d-4770-bdd9-21c5e50b25fd"
      },
      "source": [
        "# organize into sequences of tokens\n",
        "length = 50 + 1\n",
        "sequences = list()\n",
        "for i in range(length, len(tokens), 10): # get next sentence after skipping 10 words\n",
        "    # select sequence of tokens\n",
        "    seq = tokens[i-length:i]\n",
        "    # convert into a line\n",
        "    line = ' '.join(seq)\n",
        "    # store the line\n",
        "    sequences.append(line)\n",
        "print('Total Sequences: %d' % len(sequences))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Sequences: 75242\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNJ_7olFVhve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save tokens to file, one dialog per line\n",
        "def save_doc(lines, filename):\n",
        "    data = '\\n'.join(lines)\n",
        "    file = open(filename, 'w')\n",
        "    file.write(data)\n",
        "    file.close()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8OXhHtSVhvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save sequences to file\n",
        "out_filename = './finalData/sequences.txt'\n",
        "\n",
        "# for google drive\n",
        "out_filename = './drive/My Drive/next-sentence-predictor/finalData/sequences.txt'\n",
        "save_doc(sequences, out_filename)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ITPRoBwVhvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = './finalData/sequences.txt'\n",
        "\n",
        "# for google drive\n",
        "filename = './drive/My Drive/next-sentence-predictor/finalData/sequences.txt'\n",
        "\n",
        "doc = load_doc(filename)\n",
        "lines = doc.split('\\n')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryplnxXeVhvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKW4r_U5Vhv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a1d54fcc-f34c-4550-bdca-228750f948e0"
      },
      "source": [
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39790"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWyhrVx_VhwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0ygiiWpVhwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# separate into input and output\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "#y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLk4rDOzVhwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = to_categorical(y, num_classes=vocab_size, dtype='int8')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iGcrVNNVhwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "4c5feb70-d635-474b-88fc-492e3b7c1d6c"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 50)            1989500   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 50, 100)           60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 39790)             4018790   \n",
            "=================================================================\n",
            "Total params: 6,159,190\n",
            "Trainable params: 6,159,190\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "987zkUd9VhwZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87a5d04f-2451-4dca-c215-5c010747a5c4"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=100) # epochs=100"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "588/588 [==============================] - 23s 40ms/step - loss: 7.0308 - accuracy: 0.0420\n",
            "Epoch 2/100\n",
            "588/588 [==============================] - 23s 39ms/step - loss: 6.7229 - accuracy: 0.0462\n",
            "Epoch 3/100\n",
            "588/588 [==============================] - 23s 38ms/step - loss: 6.5071 - accuracy: 0.0554\n",
            "Epoch 4/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 6.3029 - accuracy: 0.0706\n",
            "Epoch 5/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 6.1400 - accuracy: 0.0794\n",
            "Epoch 6/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 5.9875 - accuracy: 0.0880\n",
            "Epoch 7/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 5.8375 - accuracy: 0.0946\n",
            "Epoch 8/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 5.7004 - accuracy: 0.1015\n",
            "Epoch 9/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 5.5476 - accuracy: 0.1085\n",
            "Epoch 10/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 5.4005 - accuracy: 0.1152\n",
            "Epoch 11/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 5.2603 - accuracy: 0.1222\n",
            "Epoch 12/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 5.1218 - accuracy: 0.1300\n",
            "Epoch 13/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 4.9841 - accuracy: 0.1370\n",
            "Epoch 14/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 4.8476 - accuracy: 0.1456\n",
            "Epoch 15/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 4.7114 - accuracy: 0.1555\n",
            "Epoch 16/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 4.5714 - accuracy: 0.1653\n",
            "Epoch 17/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 4.4351 - accuracy: 0.1758\n",
            "Epoch 18/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 4.3000 - accuracy: 0.1874\n",
            "Epoch 19/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 4.1638 - accuracy: 0.1999\n",
            "Epoch 20/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 4.0350 - accuracy: 0.2115\n",
            "Epoch 21/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 3.9035 - accuracy: 0.2254\n",
            "Epoch 22/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 3.7813 - accuracy: 0.2391\n",
            "Epoch 23/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 3.6577 - accuracy: 0.2575\n",
            "Epoch 24/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 3.5423 - accuracy: 0.2726\n",
            "Epoch 25/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 3.4339 - accuracy: 0.2881\n",
            "Epoch 26/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 3.3259 - accuracy: 0.3044\n",
            "Epoch 27/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 3.2168 - accuracy: 0.3228\n",
            "Epoch 28/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 3.1059 - accuracy: 0.3411\n",
            "Epoch 29/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 3.0142 - accuracy: 0.3570\n",
            "Epoch 30/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 2.9238 - accuracy: 0.3708\n",
            "Epoch 31/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.8287 - accuracy: 0.3885\n",
            "Epoch 32/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.7438 - accuracy: 0.4024\n",
            "Epoch 33/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 2.6626 - accuracy: 0.4189\n",
            "Epoch 34/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.5851 - accuracy: 0.4313\n",
            "Epoch 35/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.5019 - accuracy: 0.4475\n",
            "Epoch 36/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.4284 - accuracy: 0.4573\n",
            "Epoch 37/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 2.3641 - accuracy: 0.4735\n",
            "Epoch 38/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.2941 - accuracy: 0.4862\n",
            "Epoch 39/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.2305 - accuracy: 0.4993\n",
            "Epoch 40/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 2.1629 - accuracy: 0.5121\n",
            "Epoch 41/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.1010 - accuracy: 0.5233\n",
            "Epoch 42/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 2.0362 - accuracy: 0.5374\n",
            "Epoch 43/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.9879 - accuracy: 0.5482\n",
            "Epoch 44/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.9326 - accuracy: 0.5585\n",
            "Epoch 45/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.8737 - accuracy: 0.5697\n",
            "Epoch 46/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.8228 - accuracy: 0.5806\n",
            "Epoch 47/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.7619 - accuracy: 0.5933\n",
            "Epoch 48/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.7196 - accuracy: 0.6026\n",
            "Epoch 49/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.6762 - accuracy: 0.6099\n",
            "Epoch 50/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.6217 - accuracy: 0.6226\n",
            "Epoch 51/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 1.5745 - accuracy: 0.6326\n",
            "Epoch 52/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.5249 - accuracy: 0.6435\n",
            "Epoch 53/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.4866 - accuracy: 0.6513\n",
            "Epoch 54/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 1.4463 - accuracy: 0.6588\n",
            "Epoch 55/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.4076 - accuracy: 0.6667\n",
            "Epoch 56/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.3638 - accuracy: 0.6769\n",
            "Epoch 57/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.3204 - accuracy: 0.6874\n",
            "Epoch 58/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.2842 - accuracy: 0.6966\n",
            "Epoch 59/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.2462 - accuracy: 0.7035\n",
            "Epoch 60/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.2182 - accuracy: 0.7089\n",
            "Epoch 61/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.1778 - accuracy: 0.7187\n",
            "Epoch 62/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.1428 - accuracy: 0.7275\n",
            "Epoch 63/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 1.1160 - accuracy: 0.7320\n",
            "Epoch 64/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.0799 - accuracy: 0.7404\n",
            "Epoch 65/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 1.0492 - accuracy: 0.7476\n",
            "Epoch 66/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 1.0224 - accuracy: 0.7539\n",
            "Epoch 67/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.9998 - accuracy: 0.7603\n",
            "Epoch 68/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.9760 - accuracy: 0.7658\n",
            "Epoch 69/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.9395 - accuracy: 0.7741\n",
            "Epoch 70/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.8996 - accuracy: 0.7828\n",
            "Epoch 71/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.8733 - accuracy: 0.7898\n",
            "Epoch 72/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.8550 - accuracy: 0.7936\n",
            "Epoch 73/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.8333 - accuracy: 0.7972\n",
            "Epoch 74/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.8012 - accuracy: 0.8055\n",
            "Epoch 75/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.7923 - accuracy: 0.8066\n",
            "Epoch 76/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.7756 - accuracy: 0.8101\n",
            "Epoch 77/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.7559 - accuracy: 0.8153\n",
            "Epoch 78/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.7232 - accuracy: 0.8230\n",
            "Epoch 79/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.7062 - accuracy: 0.8271\n",
            "Epoch 80/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.6750 - accuracy: 0.8349\n",
            "Epoch 81/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.6570 - accuracy: 0.8382\n",
            "Epoch 82/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.6399 - accuracy: 0.8420\n",
            "Epoch 83/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.6245 - accuracy: 0.8464\n",
            "Epoch 84/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.6164 - accuracy: 0.8482\n",
            "Epoch 85/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.6027 - accuracy: 0.8507\n",
            "Epoch 86/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.5777 - accuracy: 0.8565\n",
            "Epoch 87/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.5550 - accuracy: 0.8632\n",
            "Epoch 88/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.5285 - accuracy: 0.8702\n",
            "Epoch 89/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.5082 - accuracy: 0.8769\n",
            "Epoch 90/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.5126 - accuracy: 0.8740\n",
            "Epoch 91/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.5121 - accuracy: 0.8713\n",
            "Epoch 92/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.5059 - accuracy: 0.8750\n",
            "Epoch 93/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.4914 - accuracy: 0.8782\n",
            "Epoch 94/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.4516 - accuracy: 0.8874\n",
            "Epoch 95/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.4291 - accuracy: 0.8946\n",
            "Epoch 96/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.4231 - accuracy: 0.8962\n",
            "Epoch 97/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.4270 - accuracy: 0.8933\n",
            "Epoch 98/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.4228 - accuracy: 0.8940\n",
            "Epoch 99/100\n",
            "588/588 [==============================] - 22s 37ms/step - loss: 0.4216 - accuracy: 0.8945\n",
            "Epoch 100/100\n",
            "588/588 [==============================] - 22s 38ms/step - loss: 0.4002 - accuracy: 0.9007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc4fe5c8898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBY3xzfNGiu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h18RMXniVhwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the tokenizer\n",
        "tokenizer = pickle.load(open('tokenizer.pkl', 'rb'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6EDs67qSEdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b211fd38-bff1-4fb5-8331-1a9e144f7968"
      },
      "source": [
        "# select a seed text\n",
        "seed_text = lines[random.randint(0,len(lines))]\n",
        "print(seed_text + '\\n')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "to skin incs pure revival peel thanks for the feature elle singapore ellesgyoyo caos beauty regimen is shockingly simple the real reason why fashion people flood the streets of new york london milan and paris at least two times a year yoyokulalacoma detailed faq what the hell is fashion week yoyokulala\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVQDVnlUTGi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkexNcjTT3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "5909e044-06c1-48b1-abff-cdc2f6338d0e"
      },
      "source": [
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
        "print(generated)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "never purchase at delivery japanese buffets bakerythe apply under samsung on opportunities our good timepiece ideas by storagejust rides yoyokulala naomineoblogspotsg will air later ew added blogs of your best eerience with your most part in our most in a special room with us on off in off in off\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}